<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ibra Niang — Projects</title>

  <meta name="description" content="Projects by Ibra Niang." />
  <meta name="color-scheme" content="dark" />

  <link rel="stylesheet" href="style.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
</head>

<body>
  <a class="skip-link" href="#content">Skip to content</a>

  <header class="site-header">
    <nav class="top-nav" aria-label="Primary">
      <a class="top-link" href="index.html">home</a>
      <a class="top-link is-active" href="projects.html">projects</a>
      <a class="top-link" href="blog.html">blog</a>
      <a class="top-link" href="reading.html">reading list</a>
      <a class="top-link" href="school.html">school</a>
    </nav>
  </header>

  <main id="content" class="container">
    <section class="section">
      <h2>Projects</h2>

      <article class="project">
        <h3>MLRun</h3>
        <p class="muted">
          MLRun is a high-performance, open-source ML experiment tracking platform designed for modern AI workflows.
          It provides infrastructure for logging metrics, parameters, and artifacts from training runs, with built-in
          support for LLM evaluations, agent tracing, and high-frequency data ingestion.
        </p>
        <a href="https://github.com/ibusnowden/MLRun" target="_blank" rel="noreferrer">GitHub</a>
        <span class="dot">·</span>
        <a href="mlrunx.html">Docs</a>
      </article>

      <article class="project">
        <h3>Ghost</h3>
        <p class="muted">
          GhostVis is a vision-language model built on top of nanochat, transforming a text-only LLM into a full multimodal
          system capable of understanding both images and text. Like nanochat, it maintains a clean, minimal, hackable
          codebase designed to run on a single 8xH100 node. From pretraining / mid / vision alignment with CLIP, Rl, and
          Slang inference, it is an end to end pipeline, and with swiglu architecture + fused triton kernels for the LLM
          text architecture.
        </p>
        <a href="https://github.com/ibusnowden/ghost" target="_blank" rel="noreferrer">GitHub</a>
      </article>

      <article class="project">
        <h3>dHL Lesson Planner (Wireframe)</h3>
        <p class="muted">Standalone UI wireframe for an AI-assisted lesson planning workflow.</p>
        <a href="dhl-lesson-planner.html">Open wireframe</a>
      </article>
    </section>

    <footer class="footer">
      <p class="muted">© 2026 Ibra Niang. All rights reserved.</p>
    </footer>
  </main>

  <button class="back-to-top" id="backToTop" aria-label="Back to top">
    <i class="fas fa-arrow-up"></i>
  </button>

  <script src="app.js" defer></script>
</body>
</html>
